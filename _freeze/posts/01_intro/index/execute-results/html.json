{
  "hash": "8e7ee214716860b645551f5177f0cde9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '01 Intro to Machine Learning'\njupyter: python3\n---\n\n\n![](thumbnail.jpg)\n\n# Goal: Build an image recognizer\n\n::: {#cdb89bb4 .cell execution_count=1}\n``` {.python .cell-code}\n! pip install duckduckgo-search\n```\n:::\n\n\n::: {#faa92db8 .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:21.485492Z\",\"iopub.status.busy\":\"2024-10-23T07:41:21.484926Z\",\"iopub.status.idle\":\"2024-10-23T07:41:21.494577Z\",\"shell.execute_reply\":\"2024-10-23T07:41:21.492500Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:21.485436Z\"}' execution_count=2}\n``` {.python .cell-code}\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import *\n\ndef search_images(term, max_images=30):\n    \"\"\"\n    Search for images using DuckDuckGo's search engine\n    \n    Parameters:\n    - term: search term/query (e.g., \"cars\", \"bikes\")\n    - max_images: maximum number of images to return (default 30)\n    \n    Returns:\n    - List of image URLs\n    \"\"\"\n    print(f\"Searching for '{term}'\")\n    \n    with DDGS() as ddgs:  # Create a DuckDuckGo search session\n        # Process:\n        # 1. Search for images using ddgs.images()\n        # 2. Convert results to fastcore's List type\n        # 3. Extract just the image URLs\n        return L(ddgs.images(term, max_results=max_images)).itemgot('image')\n```\n:::\n\n\nLet's start by searching for a car photo and seeing what kind of result we get. We'll start by getting URLs from a search:\n\n::: {#7b430b6d .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:25.674118Z\",\"iopub.status.busy\":\"2024-10-23T07:41:25.672918Z\",\"iopub.status.idle\":\"2024-10-23T07:41:26.456082Z\",\"shell.execute_reply\":\"2024-10-23T07:41:26.454904Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:25.674065Z\"}' execution_count=3}\n``` {.python .cell-code}\n# get images urls, in this case just 1 url\nurls =  search_images('car photos',max_images=1)\nurls[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'car photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n'https://wallup.net/wp-content/uploads/2017/11/23/533023-Lamborghini-car-car_show-photography-black_cars-luxury_cars.jpg'\n```\n:::\n:::\n\n\n..and then download a URL and take a look at it:Now let's do the same with \"bicycle \" and \"electric scooter\":\n\n::: {#7f28ccde .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:29.883251Z\",\"iopub.status.busy\":\"2024-10-23T07:41:29.882722Z\",\"iopub.status.idle\":\"2024-10-23T07:41:38.661797Z\",\"shell.execute_reply\":\"2024-10-23T07:41:38.660264Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:29.883202Z\"}' execution_count=4}\n``` {.python .cell-code}\nfrom fastdownload import download_url\ndest = 'car.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n![](index_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nNow let's do the same with \"bicycle\":\n\n::: {#61bc6f46 .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:42.016219Z\",\"iopub.status.busy\":\"2024-10-23T07:41:42.015777Z\",\"iopub.status.idle\":\"2024-10-23T07:41:46.010197Z\",\"shell.execute_reply\":\"2024-10-23T07:41:46.008767Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:42.016174Z\"}' execution_count=5}\n``` {.python .cell-code}\ndownload_url(search_images('bicycle photos', max_images=1)[0], 'bicycle.jpg', show_progress=False)\nImage.open('bicycle.jpg').to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'bicycle photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n![](index_files/figure-html/cell-6-output-2.png){}\n:::\n:::\n\n\nThe same with electric scooters\n\n::: {#d8613cfc .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:46.022415Z\",\"iopub.status.busy\":\"2024-10-23T07:41:46.021330Z\",\"iopub.status.idle\":\"2024-10-23T07:41:46.829986Z\",\"shell.execute_reply\":\"2024-10-23T07:41:46.828642Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:46.022366Z\"}' execution_count=6}\n``` {.python .cell-code}\ndownload_url(search_images('electric scooter photos', max_images=1)[0], 'scooter.jpg', show_progress=False)\nImage.open('scooter.jpg').to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'electric scooter photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n![](index_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\nOur searches seem to be giving reasonable results.  Let's grab a few examples of each of \"car\", \"bicycle\" and \"electric scooter\" photos and save each group of photos to a different folder. We will search for day and night photos to grab a range of lighting conditions.\n\n::: {#03090526 .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:51.131104Z\",\"iopub.status.busy\":\"2024-10-23T07:41:51.130669Z\",\"iopub.status.idle\":\"2024-10-23T07:44:30.471339Z\",\"shell.execute_reply\":\"2024-10-23T07:44:30.469452Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:51.131064Z\"}' execution_count=7}\n``` {.python .cell-code}\nsearches = 'car','bicycle','electric scooter'\npath = Path('car_bicycle_or_scooter')\nfrom time import sleep\n\nfor o in searches:\n    # destination, create a directory if it doesnt exist, then download images for the o term\n    # resize the images \n    dest = path/o # car_bicycle_or_scooter/car \n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)     \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'car photo'\nSearching for 'car sun photo'\nSearching for 'car shade photo'\nSearching for 'bicycle photo'\nSearching for 'bicycle sun photo'\nSearching for 'bicycle shade photo'\nSearching for 'electric scooter photo'\nSearching for 'electric scooter sun photo'\nSearching for 'electric scooter shade photo'\n```\n:::\n:::\n\n\nFolders structure after executing the code above:\n\n![](car_bicycle_or_scooter.png)\n\n# Step 2: train our model\n\nSome photos might not download correctly which could cause our model training to fail, so we'll remove them:\n\n::: {#72deeefb .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:44:31.231518Z\",\"iopub.status.busy\":\"2024-10-23T07:44:31.231100Z\",\"iopub.status.idle\":\"2024-10-23T07:44:31.881290Z\",\"shell.execute_reply\":\"2024-10-23T07:44:31.879831Z\",\"shell.execute_reply.started\":\"2024-10-23T07:44:31.231476Z\"}' execution_count=8}\n``` {.python .cell-code}\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n10\n```\n:::\n:::\n\n\nUnderstanding DataLoaders\nTo train a model, we'll need DataLoaders, which is an object that contains:\n\nA training set (the images used to create the model)\nA validation set (the images used to check the accuracy of a model)\n\nWhat goes into the DataLoaders object?\nOut of hundreds of projects, what are all the things that change from project to project to get the data in the right shape? We can split it down into these components:\n\n1. Input and Output Types\n    * Input: Images\n    * Output: Categories (car, bicycle, electric scooter)\n2. Getting Items (get_items)\n    * Gets all image files from the specified path\n    * Runs the get_image_files function\n    * Returns a list of all image files in a path\n    * Looks through directories recursively\n3. Data Splitting (splitter)\n    * Splits the data into training and validation sets randomly\n    * Uses 20% of the data for the validation set\n4. Labeling (get_y=parent_label)\n    * Uses the parent folder name as the category label\n    * Example:\n\ncar_bicycle_or_scooter/car/image1.jpg → label is \"car\"\ncar_bicycle_or_scooter/bicycle/image2.jpg → label is \"bicycle\"\n\n\n5. Image Preprocessing\n    * Before training, resize each image to 192x192 pixels\n    * Uses \"squish\" method (as opposed to cropping)\n    * 'squish' method maintains aspect ratio\n6. DataLoader Creation\n    * dataloaders(path, bs=32)\n    * Creates train and validation dataloaders\n    * bs=32 means batch size of 32 images\n\n::: {#12c5b98d .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:20:52.582456Z\",\"iopub.status.busy\":\"2024-10-23T08:20:52.582015Z\",\"iopub.status.idle\":\"2024-10-23T08:20:53.738024Z\",\"shell.execute_reply\":\"2024-10-23T08:20:53.736864Z\",\"shell.execute_reply.started\":\"2024-10-23T08:20:52.582414Z\"}' execution_count=9}\n``` {.python .cell-code}\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    # car_bicycle_or_scooter/car/image1.jpg → label is \"car\"\n    # car_bicycle_or_scooter/bicycle/image2.jpg → label is \"bicycle\"\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32) \n\ndls.show_batch(max_n=6) # shows 6 images from a batch, displays both images and their labels\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=689 height=478}\n:::\n:::\n\n\nNow we're ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes,even on a CPU! (On a GPU, it generally takes under 10 seconds...)fastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, sowe'll use that.\n\n::: {#936e0638 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:30:11.299386Z\",\"iopub.status.busy\":\"2024-10-23T08:30:11.298910Z\",\"iopub.status.idle\":\"2024-10-23T08:31:54.838394Z\",\"shell.execute_reply\":\"2024-10-23T08:31:54.837078Z\",\"shell.execute_reply.started\":\"2024-10-23T08:30:11.299329Z\"}' execution_count=10}\n``` {.python .cell-code}\n# Create a vison learner using the DataLoaders we created above, resNet18 pre-trained model, and a metrics to measure the error rate.\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.727847</td>\n      <td>0.032132</td>\n      <td>0.010676</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.083078</td>\n      <td>0.038483</td>\n      <td>0.003559</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.046047</td>\n      <td>0.027227</td>\n      <td>0.003559</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.023140</td>\n      <td>0.021595</td>\n      <td>0.003559</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n# Step 3: Use our model\n\nLet's see what the model thinks about the car we downloaded at the start:\n\n::: {#7c52d104 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:57:05.829584Z\",\"iopub.status.busy\":\"2024-10-23T08:57:05.828522Z\",\"iopub.status.idle\":\"2024-10-23T08:57:05.836230Z\",\"shell.execute_reply\":\"2024-10-23T08:57:05.834838Z\",\"shell.execute_reply.started\":\"2024-10-23T08:57:05.829531Z\"}' execution_count=11}\n``` {.python .cell-code}\nprint(\"Model classes:\", learn.dls.vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel classes: ['bicycle', 'car', 'electric scooter']\n```\n:::\n:::\n\n\n::: {#82850166 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:57:16.508143Z\",\"iopub.status.busy\":\"2024-10-23T08:57:16.507673Z\",\"iopub.status.idle\":\"2024-10-23T08:57:16.948108Z\",\"shell.execute_reply\":\"2024-10-23T08:57:16.947076Z\",\"shell.execute_reply.started\":\"2024-10-23T08:57:16.508102Z\"}' execution_count=12}\n``` {.python .cell-code}\nis_car,_,probs = learn.predict(PILImage.create('car.jpg'))\nprint(f\"This is a: {is_car}.\")\nprint(f\"Probability it's a car: {probs[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: car.\nProbability it's a car: 1.0000\n```\n:::\n:::\n\n\n::: {#4726b4d9 .cell execution='{\"iopub.execute_input\":\"2024-10-23T09:00:24.594966Z\",\"iopub.status.busy\":\"2024-10-23T09:00:24.594444Z\",\"iopub.status.idle\":\"2024-10-23T09:00:25.650688Z\",\"shell.execute_reply\":\"2024-10-23T09:00:25.649551Z\",\"shell.execute_reply.started\":\"2024-10-23T09:00:24.594925Z\"}' execution_count=13}\n``` {.python .cell-code}\nis_bicycle,_,probs = learn.predict(PILImage.create('bicycle.jpg'))\nprint(f\"This is a: {is_bicycle}.\")\nprint(f\"Probability it's a bicycle: {probs[0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: bicycle.\nProbability it's a bicycle: 1.0000\n```\n:::\n:::\n\n\n::: {#c69a3406 .cell execution='{\"iopub.execute_input\":\"2024-10-23T09:01:03.859862Z\",\"iopub.status.busy\":\"2024-10-23T09:01:03.859407Z\",\"iopub.status.idle\":\"2024-10-23T09:01:04.041246Z\",\"shell.execute_reply\":\"2024-10-23T09:01:04.039441Z\",\"shell.execute_reply.started\":\"2024-10-23T09:01:03.859822Z\"}' execution_count=14}\n``` {.python .cell-code}\nis_scooter,_,probs = learn.predict(PILImage.create('scooter.jpg'))\nprint(f\"This is a: {is_scooter}.\")\nprint(f\"Probability it's a scooter: {probs[2]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: electric scooter.\nProbability it's a scooter: 0.9997\n```\n:::\n:::\n\n\nChecking the probability of car image being classified as a bicycle.\n\n::: {#6cd09f9c .cell execution='{\"iopub.execute_input\":\"2024-10-23T09:02:07.438291Z\",\"iopub.status.busy\":\"2024-10-23T09:02:07.437820Z\",\"iopub.status.idle\":\"2024-10-23T09:02:07.848570Z\",\"shell.execute_reply\":\"2024-10-23T09:02:07.847212Z\",\"shell.execute_reply.started\":\"2024-10-23T09:02:07.438249Z\"}' execution_count=15}\n``` {.python .cell-code}\nis_car,_,probs = learn.predict(PILImage.create('car.jpg'))\nprint(f\"This is a: {is_car}.\")\nprint(f\"Probability it's a bicycle: {probs[0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: car.\nProbability it's a bicycle: 0.0000\n```\n:::\n:::\n\n\n# Further/future improvements\n\nData cleaning - manually removing unclear photos. \nData augmentation\nUsing a different pre-trained model \nDifferent learning rate\nUse more data?\n \nTo run the code yourself, check this kaggle notebook, where I've fine-tuned the model a 2nd time,  then I've used resnet34.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}