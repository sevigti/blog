{
  "hash": "6f274c0279fd73eb89637c0c5d80ca8b",
  "result": {
    "markdown": "---\ntitle: 01 Intro to Machine Learning\ndescription: Build an image recognizer\nauthor: visi\ndate: '2024-10-23'\ncategories:\n  - fastai_course\n  - chapter_1\n  - ML\ntoc: true\ntoc-title: Contents\ntoc-location: right\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    code-link: true\n    code-block-bg: true\n    code-block-border-left: '#31BAE9'\n    code-overflow: wrap\n    code-copy: hover\n---\n\n![](thumbnail.jpg)\n\n# Goal: Build an image recognizer\n\n\nFunction to search images using DuckDuckGo's search engine\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:21.485492Z\",\"iopub.status.busy\":\"2024-10-23T07:41:21.484926Z\",\"iopub.status.idle\":\"2024-10-23T07:41:21.494577Z\",\"shell.execute_reply\":\"2024-10-23T07:41:21.492500Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:21.485436Z\"}' execution_count=2}\n``` {.python .cell-code}\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import *\n\ndef search_images(term, max_images=30):\n    \"\"\"\n    Search for images using DuckDuckGo's search engine\n    \n    Parameters:\n    - term: search term/query (e.g., \"cars\", \"bikes\")\n    - max_images: maximum number of images to return (default 30)\n    \n    Returns:\n    - List of image URLs\n    \"\"\"\n    print(f\"Searching for '{term}'\")\n    \n    with DDGS() as ddgs:  # Create a DuckDuckGo search session\n        # Process:\n        # 1. Search for images using ddgs.images()\n        # 2. Convert results to fastcore's List type\n        # 3. Extract just the image URLs\n        return L(ddgs.images(term, max_results=max_images)).itemgot('image')\n```\n:::\n\n\nLet's start by searching for a car photo and seeing what kind of result we get. We'll start by getting URLs from a search:\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:25.674118Z\",\"iopub.status.busy\":\"2024-10-23T07:41:25.672918Z\",\"iopub.status.idle\":\"2024-10-23T07:41:26.456082Z\",\"shell.execute_reply\":\"2024-10-23T07:41:26.454904Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:25.674065Z\"}' execution_count=3}\n``` {.python .cell-code}\n# get images urls, in this case just 1 url\nurls =  search_images('car photos',max_images=1)\nurls[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'car photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n'https://images.pexels.com/photos/241316/pexels-photo-241316.jpeg?cs=srgb&dl=alloy-asphalt-auto-241316.jpg&fm=jpg'\n```\n:::\n:::\n\n\nThen download a URL and take a look at it:\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:29.883251Z\",\"iopub.status.busy\":\"2024-10-23T07:41:29.882722Z\",\"iopub.status.idle\":\"2024-10-23T07:41:38.661797Z\",\"shell.execute_reply\":\"2024-10-23T07:41:38.660264Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:29.883202Z\"}' execution_count=4}\n``` {.python .cell-code}\nfrom fastdownload import download_url\ndest = 'car.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n![](index_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nNow let's do the same with \"bicycle\":\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:42.016219Z\",\"iopub.status.busy\":\"2024-10-23T07:41:42.015777Z\",\"iopub.status.idle\":\"2024-10-23T07:41:46.010197Z\",\"shell.execute_reply\":\"2024-10-23T07:41:46.008767Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:42.016174Z\"}' execution_count=5}\n``` {.python .cell-code}\ndownload_url(search_images('bicycle photos', max_images=1)[0], 'bicycle.jpg', show_progress=False)\nImage.open('bicycle.jpg').to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'bicycle photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n![](index_files/figure-html/cell-6-output-2.png){}\n:::\n:::\n\n\nThe same with electric scooters\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:46.022415Z\",\"iopub.status.busy\":\"2024-10-23T07:41:46.021330Z\",\"iopub.status.idle\":\"2024-10-23T07:41:46.829986Z\",\"shell.execute_reply\":\"2024-10-23T07:41:46.828642Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:46.022366Z\"}' execution_count=6}\n``` {.python .cell-code}\ndownload_url(search_images('electric scooter', max_images=1)[0], 'scooter.jpg', show_progress=False)\nImage.open('scooter.jpg').to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'electric scooter'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n![](index_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\nOur searches seem to be giving reasonable results.  Let's grab a few examples of each of \"car\", \"bicycle\" and \"electric scooter\" photos and save each group of photos to a different folder. We will search for sun and shade photos to grab a range of lighting conditions.\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:51.131104Z\",\"iopub.status.busy\":\"2024-10-23T07:41:51.130669Z\",\"iopub.status.idle\":\"2024-10-23T07:44:30.471339Z\",\"shell.execute_reply\":\"2024-10-23T07:44:30.469452Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:51.131064Z\"}' execution_count=7}\n``` {.python .cell-code}\nsearches = 'car','bicycle','electric scooter'\npath = Path('car_bicycle_or_scooter')\nfrom time import sleep\n\nfor o in searches:\n    # destination, create a directory if it doesnt exist, then download images for the o term\n    # resize the images \n    dest = path/o # car_bicycle_or_scooter/car \n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)     \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'car photo'\nSearching for 'car sun photo'\nSearching for 'car shade photo'\nSearching for 'bicycle photo'\nSearching for 'bicycle sun photo'\nSearching for 'bicycle shade photo'\nSearching for 'electric scooter photo'\nSearching for 'electric scooter sun photo'\nSearching for 'electric scooter shade photo'\n```\n:::\n:::\n\n\nFolders structure after executing the code above:\n\n![](car_bicycle_or_scooter.png)\n\n# Step 2: train our model\n\nSome photos might not download correctly which could cause our model training to fail, so we'll remove them:\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T07:44:31.231518Z\",\"iopub.status.busy\":\"2024-10-23T07:44:31.231100Z\",\"iopub.status.idle\":\"2024-10-23T07:44:31.881290Z\",\"shell.execute_reply\":\"2024-10-23T07:44:31.879831Z\",\"shell.execute_reply.started\":\"2024-10-23T07:44:31.231476Z\"}' execution_count=8}\n``` {.python .cell-code}\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n18\n```\n:::\n:::\n\n\n## Understanding DataLoaders  \n\nTo train a model, we'll need DataLoaders, which is an object that contains:\n\nA training set (the images used to create the model)\nA validation set (the images used to check the accuracy of a model)\n\n### What goes into the DataLoaders object?\nOut of hundreds of projects, what are all the things that change from project to project to get the data in the right shape? We can split it down into these components:\n\n1. Input and Output Types\n    * Input: Images\n    * Output: Categories (car, bicycle, electric scooter)\n2. Getting Items (get_items)\n    * Gets all image files from the specified path\n    * Runs the get_image_files function\n    * Returns a list of all image files in a path\n    * Looks through directories recursively\n3. Data Splitting (splitter)\n    * Splits the data into training and validation sets randomly\n    * Uses 20% of the data for the validation set\n4. Labeling (get_y=parent_label)\n    * Uses the parent folder name as the category label\n    * Example:\n\n    car_bicycle_or_scooter/car/image1.jpg → label is \"car\"\n    car_bicycle_or_scooter/bicycle/image2.jpg → label is \"bicycle\"\n\n\n5. Image Preprocessing\n    * Before training, resize each image to 192x192 pixels\n    * Uses \"squish\" method (as opposed to cropping)\n    * 'squish' method maintains aspect ratio\n6. DataLoader Creation\n    * dataloaders(path, bs=32)\n    * Creates train and validation dataloaders\n    * bs=32 means batch size of 32 images\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T08:20:52.582456Z\",\"iopub.status.busy\":\"2024-10-23T08:20:52.582015Z\",\"iopub.status.idle\":\"2024-10-23T08:20:53.738024Z\",\"shell.execute_reply\":\"2024-10-23T08:20:53.736864Z\",\"shell.execute_reply.started\":\"2024-10-23T08:20:52.582414Z\"}' execution_count=9}\n``` {.python .cell-code}\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    # car_bicycle_or_scooter/car/image1.jpg → label is \"car\"\n    # car_bicycle_or_scooter/bicycle/image2.jpg → label is \"bicycle\"\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32) \n\ndls.show_batch(max_n=6) # shows 6 images from a batch, displays both images and their labels\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=689 height=478}\n:::\n:::\n\n\nNow we're ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes,even on a CPU! (On a GPU, it generally takes under 10 seconds...)fastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, sowe'll use that.\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T08:30:11.299386Z\",\"iopub.status.busy\":\"2024-10-23T08:30:11.298910Z\",\"iopub.status.idle\":\"2024-10-23T08:31:54.838394Z\",\"shell.execute_reply\":\"2024-10-23T08:31:54.837078Z\",\"shell.execute_reply.started\":\"2024-10-23T08:30:11.299329Z\"}' execution_count=10}\n``` {.python .cell-code}\n# Create a vison learner using the DataLoaders we created above, resNet18 pre-trained model, and a metrics to measure the error rate.\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.414254</td>\n      <td>0.011914</td>\n      <td>0.005825</td>\n      <td>00:05</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.034290</td>\n      <td>0.015446</td>\n      <td>0.005825</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.035198</td>\n      <td>0.003703</td>\n      <td>0.001942</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.013413</td>\n      <td>0.006764</td>\n      <td>0.001942</td>\n      <td>00:05</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n# Model Training Analysis  \n\nNote: On different code executions we get different results, below we state what is most likely to happen.\n\n* First row shows initial training with high train/valid loss and error rate, indicating the model is just starting to learn.  \n* Generally both losses and the error rate decrease as we train more epochs. Training for way too many epochs can cause overfitting, thus the model will perform worse.\n\n## Understanding Error Rate vs Loss  \n* Error rate is binary (right or wrong prediction)\n* Loss measures the model's confidence/uncertainty\n\n  Example:  \n    Prediction 1: Car (60% confident) ✓ Correct  \n\n    Prediction 2: Car (95% confident) ✓ Still Correct\n\n* Both have same error rate (0% - both correct)\n* But second prediction has lower loss (more confident)\n\n### Loss Improvement Analysis  \n* Model is getting more confident in its correct predictions\n* Less uncertainty in its decisions\n* Better internal representations of features\n\n## Training Evolution - better internal representation of features example  \nEarly training:  \n\"This is a car because it has wheels\" (less confident, higher loss)  \n\nLater training:  \n\"This is a car because it has wheels, specific body shape, headlights, and typical car proportions\" (more confident, lower loss)  \n\n**Changes in loss don't affect actual right/wrong decisions (error rate)**\n\n# Step 3: Use our model\n\nLet's see what the model thinks about the car we downloaded at the start:\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T08:57:05.829584Z\",\"iopub.status.busy\":\"2024-10-23T08:57:05.828522Z\",\"iopub.status.idle\":\"2024-10-23T08:57:05.836230Z\",\"shell.execute_reply\":\"2024-10-23T08:57:05.834838Z\",\"shell.execute_reply.started\":\"2024-10-23T08:57:05.829531Z\"}' execution_count=11}\n``` {.python .cell-code}\nprint(\"Model classes:\", learn.dls.vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel classes: ['bicycle', 'car', 'electric scooter']\n```\n:::\n:::\n\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T08:57:16.508143Z\",\"iopub.status.busy\":\"2024-10-23T08:57:16.507673Z\",\"iopub.status.idle\":\"2024-10-23T08:57:16.948108Z\",\"shell.execute_reply\":\"2024-10-23T08:57:16.947076Z\",\"shell.execute_reply.started\":\"2024-10-23T08:57:16.508102Z\"}' execution_count=12}\n``` {.python .cell-code}\nis_car,_,probs = learn.predict(PILImage.create('car.jpg'))\nprint(f\"This is a: {is_car}.\")\nprint(f\"Probability it's a car: {probs[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: car.\nProbability it's a car: 1.0000\n```\n:::\n:::\n\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T09:00:24.594966Z\",\"iopub.status.busy\":\"2024-10-23T09:00:24.594444Z\",\"iopub.status.idle\":\"2024-10-23T09:00:25.650688Z\",\"shell.execute_reply\":\"2024-10-23T09:00:25.649551Z\",\"shell.execute_reply.started\":\"2024-10-23T09:00:24.594925Z\"}' execution_count=13}\n``` {.python .cell-code}\nis_bicycle,_,probs = learn.predict(PILImage.create('bicycle.jpg'))\nprint(f\"This is a: {is_bicycle}.\")\nprint(f\"Probability it's a bicycle: {probs[0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: bicycle.\nProbability it's a bicycle: 1.0000\n```\n:::\n:::\n\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T09:01:03.859862Z\",\"iopub.status.busy\":\"2024-10-23T09:01:03.859407Z\",\"iopub.status.idle\":\"2024-10-23T09:01:04.041246Z\",\"shell.execute_reply\":\"2024-10-23T09:01:04.039441Z\",\"shell.execute_reply.started\":\"2024-10-23T09:01:03.859822Z\"}' execution_count=14}\n``` {.python .cell-code}\nis_scooter,_,probs = learn.predict(PILImage.create('scooter.jpg'))\nprint(f\"This is a: {is_scooter}.\")\nprint(f\"Probability it's a scooter: {probs[2]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: electric scooter.\nProbability it's a scooter: 1.0000\n```\n:::\n:::\n\n\nChecking the probability of car image being classified as a bicycle.\n\n::: {.cell execution='{\"iopub.execute_input\":\"2024-10-23T09:02:07.438291Z\",\"iopub.status.busy\":\"2024-10-23T09:02:07.437820Z\",\"iopub.status.idle\":\"2024-10-23T09:02:07.848570Z\",\"shell.execute_reply\":\"2024-10-23T09:02:07.847212Z\",\"shell.execute_reply.started\":\"2024-10-23T09:02:07.438249Z\"}' execution_count=15}\n``` {.python .cell-code}\nis_car,_,probs = learn.predict(PILImage.create('car.jpg'))\nprint(f\"This is a: {is_car}.\")\nprint(f\"Probability it's a bicycle: {probs[0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: car.\nProbability it's a bicycle: 0.0000\n```\n:::\n:::\n\n\n# Further/future improvements\n\n* Data cleaning - Manually removing unclear photos\n* Data augmentation\n* Using a different pre-trained model\n* Different learning rate\n* Use more data\n\nTo run the code yourself, check this [kaggle notebook](https://www.kaggle.com/code/elvisvisi/01-own-model?scriptVersionId=202888569), where I've fine-tuned the model a 2nd time, then I've used resnet34.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}