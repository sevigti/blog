{
  "hash": "83a58651ffc44b242a6b328e54807bea",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Step 1: Download images of cars, bikes and electric scooters'\njupyter: python3\n---\n\n::: {#ba345b69 .cell _cell_guid='b1076dfc-b9ad-4769-8c92-a6c4dae69d19' _uuid='8f2839f25d086af736a60e9eeb907d3b93b6e0e5' execution='{\"iopub.execute_input\":\"2024-10-23T07:40:43.709449Z\",\"iopub.status.busy\":\"2024-10-23T07:40:43.709045Z\",\"iopub.status.idle\":\"2024-10-23T07:40:43.733800Z\",\"shell.execute_reply\":\"2024-10-23T07:40:43.732746Z\",\"shell.execute_reply.started\":\"2024-10-23T07:40:43.709407Z\"}' execution_count=1}\n``` {.python .cell-code}\n# Input data files are available in the read-only \"../input/\" directory# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directoryimport osfor dirname, _, filenames in os.walk('/kaggle/input'):    for filename in filenames:        print(os.path.join(dirname, filename))# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n```\n:::\n\n\n1. Use DuckDuckGo to search for images of \"car\"\n2. Use DuckDuckGo to search for images of \"bicycle\"\n3. Use DuckDuckGo to search for images of \"electric scooter\"\n4. try running this model on a picture of car and see if it works\n\n::: {#a762c75f .cell execution_count=2}\n``` {.python .cell-code}\n! pip install duckduckgo-search\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRequirement already satisfied: duckduckgo-search in /home/visi/blog/.venv/lib/python3.12/site-packages (6.3.2)\r\nRequirement already satisfied: click>=8.1.7 in /home/visi/blog/.venv/lib/python3.12/site-packages (from duckduckgo-search) (8.1.7)\r\nRequirement already satisfied: primp>=0.6.4 in /home/visi/blog/.venv/lib/python3.12/site-packages (from duckduckgo-search) (0.6.4)\r\n```\n:::\n:::\n\n\n::: {#250e6abc .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:21.485492Z\",\"iopub.status.busy\":\"2024-10-23T07:41:21.484926Z\",\"iopub.status.idle\":\"2024-10-23T07:41:21.494577Z\",\"shell.execute_reply\":\"2024-10-23T07:41:21.492500Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:21.485436Z\"}' execution_count=3}\n``` {.python .cell-code}\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import *\ndef search_images(term, max_images=30):    \n    \"\"\"    Search for images using DuckDuckGo's search engine        Parameters:    - term: search term/query (e.g., \"cars\", \"bikes\")    - max_images: maximum number of images to return (default 30)        Returns:    - List of image URLs    \"\"\"       \n    print(f\"Searching for '{term}'\")    \n    with DDGS() as ddgs: \n        #Create a DuckDuckGo search session        \n        # 1. ddgs.images(term, max_results=max_images) - Search for images        # 2. L(...) - Convert results to fastcore's List type        # 3. .itemgot('image') - Extract just the image URLs        \n        return L(ddgs.images(term, max_results=max_images)).itemgot('image')\n```\n:::\n\n\nLet's start by searching for a car photo and seeing what kind of result we get. We'll start by getting URLs from a search:\n\n::: {#4eecdb85 .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:25.674118Z\",\"iopub.status.busy\":\"2024-10-23T07:41:25.672918Z\",\"iopub.status.idle\":\"2024-10-23T07:41:26.456082Z\",\"shell.execute_reply\":\"2024-10-23T07:41:26.454904Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:25.674065Z\"}' execution_count=4}\n``` {.python .cell-code}\n# get images urls, in this case just 1 url\nurls =  search_images('car photos',max_images=1)\nurls[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'car photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n'https://images.pexels.com/photos/63764/pexels-photo-63764.jpeg?cs=srgb&dl=car-cars-lamborghini-aventador-63764.jpg&fm=jpg'\n```\n:::\n:::\n\n\n..and then download a URL and take a look at it:Now let's do the same with \"bicycle \" and \"electric scooter\":\n\n::: {#8e491ec7 .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:29.883251Z\",\"iopub.status.busy\":\"2024-10-23T07:41:29.882722Z\",\"iopub.status.idle\":\"2024-10-23T07:41:38.661797Z\",\"shell.execute_reply\":\"2024-10-23T07:41:38.660264Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:29.883202Z\"}' execution_count=5}\n``` {.python .cell-code}\nfrom fastdownload import download_url\ndest = 'car.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n![](01-own-model_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\nNow let's do the same with \"bicycle\":\n\n::: {#bc5c1270 .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:42.016219Z\",\"iopub.status.busy\":\"2024-10-23T07:41:42.015777Z\",\"iopub.status.idle\":\"2024-10-23T07:41:46.010197Z\",\"shell.execute_reply\":\"2024-10-23T07:41:46.008767Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:42.016174Z\"}' execution_count=6}\n``` {.python .cell-code}\ndownload_url(search_images('bicycle photos', max_images=1)[0], 'bicycle.jpg', show_progress=False)\nImage.open('bicycle.jpg').to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'bicycle photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n![](01-own-model_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\nThe same with electric scooters\n\n::: {#4b44172e .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:46.022415Z\",\"iopub.status.busy\":\"2024-10-23T07:41:46.021330Z\",\"iopub.status.idle\":\"2024-10-23T07:41:46.829986Z\",\"shell.execute_reply\":\"2024-10-23T07:41:46.828642Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:46.022366Z\"}' execution_count=7}\n``` {.python .cell-code}\ndownload_url(search_images('electric scooter photos', max_images=1)[0], 'scooter.jpg', show_progress=False)\nImage.open('scooter.jpg').to_thumb(256,256)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'electric scooter photos'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n![](01-own-model_files/figure-html/cell-8-output-2.png){}\n:::\n:::\n\n\nOur searches seem to be giving reasonable results.  Let's grab a few examples of each of \"car\", \"bicycle\" and \"electric scooter\" photos and save each group of photos to a different folder. We will search for day and night photos to grab a range of lighting conditions.\n\n::: {#3e0b3dde .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:41:51.131104Z\",\"iopub.status.busy\":\"2024-10-23T07:41:51.130669Z\",\"iopub.status.idle\":\"2024-10-23T07:44:30.471339Z\",\"shell.execute_reply\":\"2024-10-23T07:44:30.469452Z\",\"shell.execute_reply.started\":\"2024-10-23T07:41:51.131064Z\"}' execution_count=8}\n``` {.python .cell-code}\nsearches = 'car','bicycle','electric scooter'\npath = Path('car_bicycle_or_scooter')\nfrom time import sleep\n\nfor o in searches:\n    # destination, create a directory if it doesnt exist, then download images for the o term\n    # resize the images \n    dest = path/o # car_bicycle_or_scooter/car \n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)     \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSearching for 'car photo'\nSearching for 'car sun photo'\nSearching for 'car shade photo'\nSearching for 'bicycle photo'\nSearching for 'bicycle sun photo'\nSearching for 'bicycle shade photo'\nSearching for 'electric scooter photo'\nSearching for 'electric scooter sun photo'\nSearching for 'electric scooter shade photo'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/visi/blog/.venv/lib/python3.12/site-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n```\n:::\n:::\n\n\n![Alt Text](car_bicycle_or_scooter.png)\n\n# Step 2: train our model\n\nSome photos might not download correctly which could cause our model training to fail, so we'll remove them:\n\n::: {#2090b6ce .cell execution='{\"iopub.execute_input\":\"2024-10-23T07:44:31.231518Z\",\"iopub.status.busy\":\"2024-10-23T07:44:31.231100Z\",\"iopub.status.idle\":\"2024-10-23T07:44:31.881290Z\",\"shell.execute_reply\":\"2024-10-23T07:44:31.879831Z\",\"shell.execute_reply.started\":\"2024-10-23T07:44:31.231476Z\"}' execution_count=9}\n``` {.python .cell-code}\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n29\n```\n:::\n:::\n\n\nTo train a model, we'll need DataLoaders, which is an  object that contains a training set(the images used to create the model) and a validation set(the images used to check the accuracy of a model)  What goes into the DataLoaders object? Out of hundreds of projects what are all the things that change from project to project to get the data in the right shape? We could basically split it down into these five things.  1. What kind of input and output do we have? Input- images. Output- categories, a number of possibities(car, bicycle, electric scooter)2. get_items -> Gets all image files from the specified path, run the get_image_files function (which returns a list of all image files in a path). Looks through directories recursively3. Splitter -Split the data into training and validation sets randomly, using 20% of the data for the validation set.4. get_y=parent_label - Uses the parent folder name as the category label5. Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it).'squish' method maintains aspect ratio6. dataloaders(path, bs=32) - Creates train and validation dataloaders, bs=32 means batch size of 32 images.\n\n::: {#870d4267 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:20:52.582456Z\",\"iopub.status.busy\":\"2024-10-23T08:20:52.582015Z\",\"iopub.status.idle\":\"2024-10-23T08:20:53.738024Z\",\"shell.execute_reply\":\"2024-10-23T08:20:53.736864Z\",\"shell.execute_reply.started\":\"2024-10-23T08:20:52.582414Z\"}' execution_count=10}\n``` {.python .cell-code}\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    # car_bicycle_or_scooter/car/image1.jpg → label is \"car\"\n    # car_bicycle_or_scooter/bicycle/image2.jpg → label is \"bicycle\"\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32) \n\ndls.show_batch(max_n=6) # shows 6 images from a batch, displays both images and their labels\n```\n\n::: {.cell-output .cell-output-display}\n![](01-own-model_files/figure-html/cell-11-output-1.png){width=689 height=478}\n:::\n:::\n\n\nNow we're ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes,even on a CPU! (On a GPU, it generally takes under 10 seconds...)fastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, sowe'll use that.\n\n::: {#1f3edf90 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:30:11.299386Z\",\"iopub.status.busy\":\"2024-10-23T08:30:11.298910Z\",\"iopub.status.idle\":\"2024-10-23T08:31:54.838394Z\",\"shell.execute_reply\":\"2024-10-23T08:31:54.837078Z\",\"shell.execute_reply.started\":\"2024-10-23T08:30:11.299329Z\"}' execution_count=11}\n``` {.python .cell-code}\n# Create a vison learner using the DataLoaders we created above, resNet18 pre-trained model, and a metrics to measure the error rate.\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.042422</td>\n      <td>0.153208</td>\n      <td>0.049645</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.129953</td>\n      <td>0.031034</td>\n      <td>0.014184</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.088246</td>\n      <td>0.064510</td>\n      <td>0.035461</td>\n      <td>00:01</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.061246</td>\n      <td>0.048250</td>\n      <td>0.035461</td>\n      <td>00:01</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nFirst row - initial training with high error rate, 12.7%, indicates the model is just starting to learn.  \n1. Loss Trends:  \n    * Train_loss: 1.70 → 0.60 → 0.36 → 0.25\n    * Valid_loss: 0.36 → 0.21 → 0.15 → 0.16\n    * Both losses consistently decreasing\n2. Error Rate Pattern:\n    * Big improvement in first fine-tuning epoch (12.77% → 4.26%)\n    * After the other epochs, no fluctuation  at all in error rate.\n3. Model Performance:\n    * Final error rate of 4.26% is quite good\n    * Might have reached optimal performance for this architecture/dataset, judging by the error rate decreasing after the first epoch, then not changing at all.\n\nConclusion:  \n   1. Model has converged\n   2. Dataset might be small\n   3. Further training probably won't improve performance\n\nError Rate vs Loss:\n\nError rate is binary (right or wrong prediction)\nLoss measures the model's confidence/uncertainty  \n \nExample: \nPrediction 1: Car (60% confident) ✓ Correct\nPrediction 2: Car (95% confident) ✓ Still Correct  \n* Both have same error rate (0% - both correct)\n* But second prediction has lower loss (more confident)\n  \nWhat's happening in our case:  \nEpoch 0: 4.26% error, but less confident predictions\nEpoch 1: 4.26% error, but more confident predictions\nEpoch 2: 4.26% error, but even more confident predictions  \n\nLoss Improvement Means:\n\n* Model is getting more confident in its correct predictions\n* Less uncertainty in its decisions\n* Better internal representations -  how the neural network understands and represents features in the data.   \nEarly training:\nModel: \"This is a car because it has wheels\" (less confident, higher loss)\n\nLater training:\nModel: \"This is a car because it has wheels, specific body shape, headlights, and typical car proportions\" (more confident, lower loss)  \n\n* But not enough to change the actual right/wrong decisions (error rate)\n\nThis is actually healthy behavior - the model is becoming more robust even though the error rate isn't changing.\n\n\n\nTO be revisited in the future. Data cleaning, data augmentation, different models, different learning rate.\n\n# Step 3: Use our model\n\nLet's see what the model thinks about the car we downloaded at the start:\n\n::: {#a63dcf33 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:57:05.829584Z\",\"iopub.status.busy\":\"2024-10-23T08:57:05.828522Z\",\"iopub.status.idle\":\"2024-10-23T08:57:05.836230Z\",\"shell.execute_reply\":\"2024-10-23T08:57:05.834838Z\",\"shell.execute_reply.started\":\"2024-10-23T08:57:05.829531Z\"}' execution_count=12}\n``` {.python .cell-code}\nprint(\"Model classes:\", learn.dls.vocab)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel classes: ['bicycle', 'car', 'electric scooter']\n```\n:::\n:::\n\n\n::: {#d0963417 .cell execution='{\"iopub.execute_input\":\"2024-10-23T08:57:16.508143Z\",\"iopub.status.busy\":\"2024-10-23T08:57:16.507673Z\",\"iopub.status.idle\":\"2024-10-23T08:57:16.948108Z\",\"shell.execute_reply\":\"2024-10-23T08:57:16.947076Z\",\"shell.execute_reply.started\":\"2024-10-23T08:57:16.508102Z\"}' execution_count=13}\n``` {.python .cell-code}\nis_car,_,probs = learn.predict(PILImage.create('car.jpg'))\nprint(f\"This is a: {is_car}.\")\nprint(f\"Probability it's a car: {probs[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: car.\nProbability it's a car: 0.9999\n```\n:::\n:::\n\n\n::: {#b79d9d68 .cell execution='{\"iopub.execute_input\":\"2024-10-23T09:00:24.594966Z\",\"iopub.status.busy\":\"2024-10-23T09:00:24.594444Z\",\"iopub.status.idle\":\"2024-10-23T09:00:25.650688Z\",\"shell.execute_reply\":\"2024-10-23T09:00:25.649551Z\",\"shell.execute_reply.started\":\"2024-10-23T09:00:24.594925Z\"}' execution_count=14}\n``` {.python .cell-code}\nis_bicycle,_,probs = learn.predict(PILImage.create('bicycle.jpg'))\nprint(f\"This is a: {is_bicycle}.\")\nprint(f\"Probability it's a bicycle: {probs[0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: bicycle.\nProbability it's a bicycle: 1.0000\n```\n:::\n:::\n\n\n::: {#921eb950 .cell execution='{\"iopub.execute_input\":\"2024-10-23T09:01:03.859862Z\",\"iopub.status.busy\":\"2024-10-23T09:01:03.859407Z\",\"iopub.status.idle\":\"2024-10-23T09:01:04.041246Z\",\"shell.execute_reply\":\"2024-10-23T09:01:04.039441Z\",\"shell.execute_reply.started\":\"2024-10-23T09:01:03.859822Z\"}' execution_count=15}\n``` {.python .cell-code}\nis_scooter,_,probs = learn.predict(PILImage.create('scooter.jpg'))\nprint(f\"This is a: {is_scooter}.\")\nprint(f\"Probability it's a scooter: {probs[2]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: electric scooter.\nProbability it's a scooter: 1.0000\n```\n:::\n:::\n\n\nChecking the probability of car image being classified as a bicycle.\n\n::: {#73871be3 .cell execution='{\"iopub.execute_input\":\"2024-10-23T09:02:07.438291Z\",\"iopub.status.busy\":\"2024-10-23T09:02:07.437820Z\",\"iopub.status.idle\":\"2024-10-23T09:02:07.848570Z\",\"shell.execute_reply\":\"2024-10-23T09:02:07.847212Z\",\"shell.execute_reply.started\":\"2024-10-23T09:02:07.438249Z\"}' execution_count=16}\n``` {.python .cell-code}\nis_car,_,probs = learn.predict(PILImage.create('car.jpg'))\nprint(f\"This is a: {is_car}.\")\nprint(f\"Probability it's a bicycle: {probs[0]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is a: car.\nProbability it's a bicycle: 0.0000\n```\n:::\n:::\n\n\n",
    "supporting": [
      "01-own-model_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}